# -*- coding: utf-8 -*-
import streamlit as st
import base64
import os
import json
import pandas as pd
from typing import List, Dict
import html # HTML ì´ìŠ¤ì¼€ì´í”„ë¥¼ ìœ„í•´ ì¶”ê°€

from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from textwrap import fill

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage

# ==========================================
# ğŸ”¹ ìƒìˆ˜ ì •ì˜ (ëª¨ë¸ ë° ì¸ë±ìŠ¤)
# ==========================================
EMBEDDING_MODEL = "jeffh/intfloat-multilingual-e5-large-instruct:q8_0"
CHAT_MODEL = "llama3.1:8b"

FAISS_INDEX_DRUG = "faiss_drug_index"
FAISS_INDEX_DISEASE = "faiss_disease_index"
FAISS_INDEX_PROCEDURE = "faiss_procedure_index"

# [!!!] ìˆ˜ì •: ì„ê³„ê°’(THRESHOLD) ìì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ë¡œì§ì„ ë³€ê²½í•©ë‹ˆë‹¤.
# RELEVANCE_THRESHOLD = 1.3 # <-- ì´ ë³€ìˆ˜ë¥¼ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

# ==========================================
# ğŸ”¹ ë°±ì—”ë“œ: ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´
# ==========================================

# e5-instruct ëª¨ë¸ì˜ ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•(passage:/query:)ìœ¼ë¡œ ë³€ê²½
class InstructEmbeddings(OllamaEmbeddings):
    """ 'passage:'ì™€ 'query:'ë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ì„ë² ë”© """
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        # DBì— ì €ì¥ë˜ëŠ” ë¬¸ì„œëŠ” 'passage:'ë¥¼ ì‚¬ìš©
        instructed_texts = [f"passage: {text}" for text in texts]
        print(f"--- ğŸ“„ {len(instructed_texts)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì¤‘... (Prefix: 'passage:') ---")
        return super().embed_documents(instructed_texts)
    
    def embed_query(self, text: str) -> List[float]:
        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ 'query:'ë¥¼ ì‚¬ìš©
        instructed_text = f"query: {text}"
        print(f"--- â“ ì¿¼ë¦¬ ì„ë² ë”© ì¤‘... (Prefix: 'query:') ---")
        return super().embed_documents([instructed_text])[0]

@st.cache_resource
def get_embeddings():
    try:
        embeddings = InstructEmbeddings(model=EMBEDDING_MODEL)
        return embeddings
    except Exception as e:
        st.error(f"âŒ ì„ë² ë”© ëª¨ë¸({EMBEDDING_MODEL}) ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}"); st.stop()

def load_or_create_faiss_index(index_path: str, documents: List[Document], embeddings: InstructEmbeddings):
    # [!!!] ì¤‘ìš”: ìƒˆ ì½”ë“œë¡œ ì‹¤í–‰í•˜ê¸° ì „, ë°˜ë“œì‹œ 'faiss_...' í´ë” 3ê°œë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œí•´ì•¼ í•©ë‹ˆë‹¤!
    if os.path.exists(index_path):
        try:
            print(f"--- ğŸš€ ë¡œì»¬ ì¸ë±ìŠ¤({index_path}) ë¡œë”© ì‹œë„... ---")
            vector_store = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
            print("--- âœ… ë¡œì»¬ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ ---")
            return vector_store
        except Exception as e:
            st.warning(f"âš ï¸ ë¡œì»¬ ì¸ë±ìŠ¤({index_path}) ë¡œë“œ ì‹¤íŒ¨({e}). ìƒˆ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    try:
        print(f"--- â³ ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ({index_path}) ---")
        vector_store = FAISS.from_documents(documents, embeddings)
        vector_store.save_local(index_path)
        print(f"--- âœ… ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° {index_path}ì— ì €ì¥ ì™„ë£Œ ---")
        return vector_store
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì„ë² ë”©/ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ({index_path}): {e}"); st.stop()

@st.cache_resource
def load_drug_data(_embeddings):
    print("--- ğŸ©º [1/3] ì•½ë¬¼ ë°ì´í„° ë¡œë”© ì‹œì‘ ---")
    try:
        with open("drug_list.json", "r", encoding="utf-8") as f:
            j = json.load(f); all_items = j['body']['items'] if 'body' in j else (j if isinstance(j, list) else [])
    except FileNotFoundError: st.error("âŒ drug_list.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    all_documents = []
    for item in all_items:
        base_metadata = { "ì œí’ˆëª…": item.get('itemName', 'N/A'), "ì—…ì²´ëª…": item.get('entpName', 'N/A'), "source": "drug_list.json" }
        sections = {"íš¨ëŠ¥": item.get('efcyQesitm', 'N/A'), "ì‚¬ìš©ë²•": item.get('useMethodQesitm', 'N/A'), "ì£¼ì˜ì‚¬í•­ê²½ê³ ": item.get('atpnWarnQesitm', 'N/A'), "ì£¼ì˜ì‚¬í•­": item.get('atpnQesitm', 'N/A'), "ìƒí˜¸ì‘ìš©": item.get('intrcQesitm', 'N/A'), "ë¶€ì‘ìš©": item.get('seQesitm', 'N/A'), "ë³´ê´€ë²•": item.get('depositMethodQesitm', 'N/A')}
        for sec_name, sec_content in sections.items():
            if sec_content not in ('N/A', '', None, ' '):
                all_documents.append(Document(page_content=f"{sec_name}: {sec_content}", metadata={**base_metadata, "section": sec_name}))
    if not all_documents: st.error("âŒ drug_list.jsonì—ì„œ ìœ íš¨í•œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()
    return load_or_create_faiss_index(FAISS_INDEX_DRUG, all_documents, _embeddings), len(all_items)

@st.cache_resource
def load_disease_data(_embeddings):
    print("--- ğŸ©º [2/3] ì§ˆë³‘/ì¦ìƒ ë°ì´í„° ë¡œë”© ì‹œì‘ ---")
    try: df = pd.read_csv("textbook.csv")
    except FileNotFoundError: st.error("âŒ textbook.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    if "content" not in df.columns: st.error("âŒ textbook.csv íŒŒì¼ì— 'content' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    all_documents = [Document(page_content=row["content"], metadata={"source": "textbook.csv"}) for _, row in df.iterrows() if pd.notna(row["content"]) and row["content"].strip()]
    if not all_documents: st.error("âŒ textbook.csvì—ì„œ ìœ íš¨í•œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()
    return load_or_create_faiss_index(FAISS_INDEX_DISEASE, all_documents, _embeddings), len(all_documents)

@st.cache_resource
def load_procedure_data(_embeddings):
    print("--- ğŸ©º [3/3] ìˆ˜ìˆ /ì‹œìˆ  ë°ì´í„° ë¡œë”© ì‹œì‘ ---")
    try: df = pd.read_csv("etc.csv")
    except FileNotFoundError: st.error("âŒ etc.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    if "content" not in df.columns: st.error("âŒ etc.csv íŒŒì¼ì— 'content' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    all_documents = [Document(page_content=row["content"], metadata={"source": "etc.csv"}) for _, row in df.iterrows() if pd.notna(row["content"]) and row["content"].strip()]
    if not all_documents: st.error("âŒ etc.csvì—ì„œ ìœ íš¨í•œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()
    return load_or_create_faiss_index(FAISS_INDEX_PROCEDURE, all_documents, _embeddings), len(all_documents)


# ==========================================
# ğŸ”¹ ë°±ì—”ë“œ: ë°ì´í„° ë¡œë”© ì‹¤í–‰
# ==========================================
embeddings = get_embeddings()
with st.spinner(f"ğŸ©º ì˜ë£Œ ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì¤‘... (Embedding: {EMBEDDING_MODEL})"):
    vector_store_drug, num_drugs = load_drug_data(embeddings)
    vector_store_disease, num_diseases = load_disease_data(embeddings)
    vector_store_procedure, num_procedures = load_procedure_data(embeddings)
    if not all([vector_store_drug, vector_store_disease, vector_store_procedure]):
        st.error("ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•±ì„ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”."); st.stop()

# ==========================================
# ğŸ”¹ ë°±ì—”ë“œ: 4-Chain ì •ì˜
# ==========================================

# --- 1. ì§ˆë¬¸ ì¬ì‘ì„±ê¸° (Contextualizer) ---
@st.cache_resource
def get_contextualizer_chain():
    try:
        contextualizer_model = ChatOllama(model=CHAT_MODEL, temperature=0.0)
        contextualizer_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ 'ëŒ€í™” ê¸°ë¡'ì„ ë°”íƒ•ìœ¼ë¡œ 'ìƒˆ ì§ˆë¬¸'ì„ ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•œ 'ì™„ì „í•œ ì§ˆë¬¸'ìœ¼ë¡œ ì¬ì‘ì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.
- 'ìƒˆ ì§ˆë¬¸'ì´ 'ê·¸ê±°', 'ì €ê±°', 'ì–´ë•Œ' ë“± ë§¥ë½ì— ì˜ì¡´í•œë‹¤ë©´, 'ëŒ€í™” ê¸°ë¡'ì„ ì°¸ê³ í•˜ì—¬ ì™„ì „í•œ ì§ˆë¬¸ìœ¼ë¡œ ë§Œë“œì„¸ìš”.
- 'ìƒˆ ì§ˆë¬¸'ì´ ì´ë¯¸ ì™„ì „í•˜ë‹¤ë©´, ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
- ì˜¤ì§ ì¬ì‘ì„±ëœ ì§ˆë¬¸ "í•œ ë¬¸ì¥"ë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.
"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "ìƒˆ ì§ˆë¬¸: {question}")
        ])
        return contextualizer_prompt | contextualizer_model | StrOutputParser()
    except Exception as e:
        st.error(f"âŒ ì§ˆë¬¸ ì¬ì‘ì„±ê¸° ëª¨ë¸({CHAT_MODEL}) ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}"); st.stop()

# --- 2. ë¼ìš°í„°(Router) ---
@st.cache_resource
def get_router_chain():
    try:
        router_model = ChatOllama(model=CHAT_MODEL, temperature=0)
        router_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ 'ì•½ë¬¼', 'ì§ˆë³‘', 'ìˆ˜ìˆ ' ì„¸ ê°€ì§€ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤.
- 'ì•½'ì— ëŒ€í•´ ë¬¼ìœ¼ë©´ 'drug'
- 'ë³‘'ì´ë‚˜ 'ì¦ìƒ'ì— ëŒ€í•´ ë¬¼ìœ¼ë©´ 'disease'
- 'ìˆ˜ìˆ 'ì´ë‚˜ 'ì‹œìˆ 'ì— ëŒ€í•´ ë¬¼ìœ¼ë©´ 'procedure'
- ì–´ëŠ ê²ƒì—ë„ í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ 'general'
ì´ë¼ê³ , ë°˜ë“œì‹œ í•œ ë‹¨ì–´ë¡œë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.
"""),
            ("user", "{question}")
        ])
        return router_prompt | router_model | StrOutputParser()
    except Exception as e:
        st.error(f"âŒ ë¼ìš°í„° ëª¨ë¸({CHAT_MODEL}) ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}"); st.stop()

# --- 3. ìš”ì•½ê¸°(Summarizer) ---
@st.cache_resource
def get_summarizer_chain():
    try:
        summarizer_model = ChatOllama(model=CHAT_MODEL)
        summarizer_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ 'ì°¸ê³  ìë£Œ'ì™€ 'ëŒ€í™” ê¸°ë¡'ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ 'í˜„ì¬ ì§ˆë¬¸'ì— ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì˜ë£Œ ì¡°ìˆ˜ì…ë‹ˆë‹¤.

[ì¤‘ìš” ì›ì¹™]
1.  **ìë£Œ ê¸°ë°˜ ë‹µë³€ (Grounding):** ë‹¹ì‹ ì€ **ì˜¤ì§** ì œê³µëœ 'ì°¸ê³  ìë£Œ'ì˜ ë‚´ìš©ì„ **ìš”ì•½**í•˜ê±°ë‚˜ **ì¸ìš©**í•´ì•¼ í•©ë‹ˆë‹¤. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
2.  **ì¹œì ˆí•œ í†¤:** ì „ë¬¸ê°€ì˜ ì…ì¥ì—ì„œ, í•˜ì§€ë§Œ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë§íˆ¬ë¡œ ë‹µë³€í•˜ì„¸ìš”.
3.  **ìë£Œ ì—†ìŒ ì²˜ë¦¬:** 'ì°¸ê³  ìë£Œ'ê°€ "ê²€ìƒ‰ëœ ì•½ë¬¼ ìë£Œ ì¤‘ ê´€ë ¨ì„±ì´ ë†’ì€ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤." ë˜ëŠ” "ê²€ìƒ‰ëœ ì§ˆë³‘/ì¦ìƒ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤." ë˜ëŠ” "ê²€ìƒ‰ëœ ìˆ˜ìˆ /ì‹œìˆ  ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë°˜í™˜ë˜ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
4.  ì‚¬ìš©ìì˜ 'í˜„ì¬ ì§ˆë¬¸'ì— ëŒ€í•œ ë‹µë³€ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. 'ëŒ€í™” ê¸°ë¡'ì„ ì°¸ê³ í•˜ì—¬ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”.
"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "ì°¸ê³  ìë£Œ: \n{context}\n\ní˜„ì¬ ì§ˆë¬¸: {question}")
        ])
        return summarizer_prompt | summarizer_model | StrOutputParser()
    except Exception as e:
        st.error(f"âŒ ìš”ì•½ê¸° ëª¨ë¸({CHAT_MODEL}) ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}"); st.stop()

# --- 4. ì¶”ì²œ ì§ˆë¬¸ ìƒì„±ê¸°(Recommender) ---
@st.cache_resource
def get_recommender_chain():
    try:
        recommender_model = ChatOllama(model=CHAT_MODEL, temperature=0.5) 
        recommender_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” 'í›„ì† ì§ˆë¬¸'ì„ ì œì•ˆí•˜ëŠ” AI ì¡°ìˆ˜ì…ë‹ˆë‹¤.
ì œê³µëœ 'AI ë‹µë³€'ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ë‹¤ìŒì— ê¶ê¸ˆí•´í•  ë§Œí•œ 3ê°€ì§€ì˜ ì§§ê³  ê´€ë ¨ì„± ë†’ì€ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

[ì¤‘ìš” ê·œì¹™]
- 'AI ë‹µë³€'ì´ "ì£„ì†¡í•©ë‹ˆë‹¤", "ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" ë“± ê±°ì ˆì˜ ë‚´ìš©ì´ë¼ë©´, "ì •ë³´ ì—†ìŒ"ì´ë¼ê³ ë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.
- ê° ì§ˆë¬¸ì€ 'â€¢ 'ë¡œ ì‹œì‘í•˜ê³ , ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.
- ì˜¤ì§ 3ê°œì˜ ì§ˆë¬¸ë§Œ ìƒì„±í•˜ê³ , ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
"""),
            ("user", "AI ë‹µë³€:\n{answer}")
        ])
        return recommender_prompt | recommender_model | StrOutputParser()
    except Exception as e:
        st.error(f"âŒ ì¶”ì²œ ëª¨ë¸({CHAT_MODEL}) ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}"); st.stop()

# ì²´ì¸ ë¡œë“œ
contextualizer_chain = get_contextualizer_chain()
router_chain = get_router_chain()
summarizer_chain = get_summarizer_chain()
recommender_chain = get_recommender_chain()


# ==========================================
# ğŸ”¹ ë°±ì—”ë“œ: ê²€ìƒ‰ ë„êµ¬ (Retriever)
# ==========================================

def retrieve_drug_info(query: str, k: int):
    """[ì•½ì‚¬] 'íš¨ëŠ¥' ì„¹ì…˜ì„ ìš°ì„ ìˆœìœ„ë¡œ ì¬ì •ë ¬."""
    
    # [!!!] ìˆ˜ì •: 'similarity_search' -> 'max_marginal_relevance_search'ë¡œ ë³€ê²½
    # 'k=k*2' (e.g., 8)ê°œì˜ ë‹¤ì–‘í•œ ë¬¸ì„œë¥¼ ë¨¼ì € ì°¾ìŒ
    # 'fetch_k=50' (50ê°œ) ë¬¸ì„œë¥¼ ë¯¸ë¦¬ ë³´ê³  ê·¸ ì¤‘ì—ì„œ k*2ê°œë¥¼ ê³ ë¦„
    retrieved_docs = vector_store_drug.max_marginal_relevance_search(
        query, 
        k=k*2,    
        fetch_k=50 
    ) 
    
    if retrieved_docs:
        top_5_names = [doc.metadata.get("ì œí’ˆëª…", "N/A") for doc in retrieved_docs[:5]]
        print(f"--- ğŸ” [Debug-MMR] Diverse docs for '{query}': {top_5_names} ---")
    
    # [!!!] ìˆ˜ì •: MMRì€ (doc, score)ê°€ ì•„ë‹Œ doc ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, score(x[1]) ì •ë ¬ ì œê±°
    re_ranked_docs = sorted(
        retrieved_docs, # MMRë¡œ ì°¾ì€ ë‹¤ì–‘í•œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        key=lambda x: (0 if x.metadata.get("section") == "íš¨ëŠ¥" else 1)
        # 1ìˆœìœ„: íš¨ëŠ¥, 2ìˆœìœ„: (ì›ë˜ ìˆœì„œ - MMRì´ ì´ë¯¸ ë³´ì¥)
    )
    
    # ì¬ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ kê°œ ì„ íƒ
    final_docs = re_ranked_docs[:k]
    
    if not final_docs:
        return "ê²€ìƒ‰ëœ ì•½ë¬¼ ìë£Œ ì¤‘ ê´€ë ¨ì„±ì´ ë†’ì€ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤." 
    
    formatted_docs = []
    for i, doc in enumerate(final_docs, 1):
        item_name = doc.metadata.get("ì œí’ˆëª…", "N/A")
        section_name = doc.metadata.get("section", "ì •ë³´ ì—†ìŒ") 
        formatted_docs.append(
            f"ğŸ“˜ [ì•½ë¬¼ ìë£Œ {i}] {item_name} (ì„¹ì…˜: {section_name})\n{'-'*20}\n{doc.page_content.strip()}"
        )
    return "\n\n".join(formatted_docs)

def retrieve_disease_info(query: str, k: int):
    """[ì˜ì‚¬] ì§ˆë³‘/ì¦ìƒ ê²€ìƒ‰ (ì„ê³„ê°’ ì œê±°)"""
    # [!!!] ìˆ˜ì •: ì„ê³„ê°’(Threshold) í•„í„°ë§ ë¡œì§ì„ ì™„ì „íˆ ì œê±°
    retrieved_docs = vector_store_disease.similarity_search(query, k=k)

    if not retrieved_docs: 
        return "ê²€ìƒ‰ëœ ì§ˆë³‘/ì¦ìƒ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤." 
    
    formatted_docs = []
    for i, doc in enumerate(retrieved_docs, 1):
        formatted_docs.append(
            f"ğŸ“— [ì§ˆë³‘/ì¦ìƒ ìë£Œ {i}]\n{'-'*20}\n{doc.page_content.strip()}"
        )
    return "\n\n".join(formatted_docs)

def retrieve_procedure_info(query: str, k: int):
    """[ì™¸ê³¼ì˜] ìˆ˜ìˆ /ì‹œìˆ  ê²€ìƒ‰ (ì„ê³„ê°’ ì œê±°)"""
    # [!!!] ìˆ˜ì •: ì„ê³„ê°’(Threshold) í•„í„°ë§ ë¡œì§ì„ ì™„ì „íˆ ì œê±°
    retrieved_docs = vector_store_procedure.similarity_search(query, k=k)

    if not retrieved_docs: 
        return "ê²€ìƒ‰ëœ ìˆ˜ìˆ /ì‹œìˆ  ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤." 
    
    formatted_docs = []
    for i, doc in enumerate(retrieved_docs, 1):
        formatted_docs.append(
            f"ğŸ“™ [ìˆ˜ìˆ /ì‹œìˆ  ìë£Œ {i}]\n{'-'*20}\n{doc.page_content.strip()}"
        )
    return "\n\n".join(formatted_docs)


# ==========================================
# ğŸ”¹ UI: ìœ í‹¸ (ì´ë¯¸ì§€ â†’ base64 ë³€í™˜)
# ==========================================
@st.cache_data
def img_to_base64(path):
    # .pngë¥¼ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ .jpgë¥¼ ì‹œë„
    if not os.path.exists(path):
        jpg_path = path.replace(".png", ".jpg")
        if os.path.exists(jpg_path):
            path = jpg_path
        else:
            st.warning(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path} ë˜ëŠ” {jpg_path}. ê¸°ë³¸ í—¤ë”ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return None
            
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode()

blue64 = img_to_base64("blue_medi.png") 
pink64 = img_to_base64("pink_medi.png")

# ==========================================
# ğŸ”¹ UI: í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ğŸ’Š SafeMedi AI", layout="wide")

# ==========================================
# ğŸ”¹ UI: ì „ì—­ ìŠ¤íƒ€ì¼ (CSS)
# ==========================================
st.markdown("""
<style>
:root{
  --bg:#f8fbfd;
  --card:#ffffff;
  --mint:#A8E6CF;
  --sky:#B8E4F0;
  --coral:#FF9AA2;
  --ink:#1f2937;
  --sub:#6b7280;
  --ring: 0 0 0 3px rgba(184,228,240,.35);
}
html, body, [data-testid="stAppViewContainer"] { background: var(--bg) !important; }
header[data-testid="stHeader"] { background: transparent; }
section.block-container{ padding-top: 1.2rem; max-width: 960px; }
h1,h2,h3 { font-weight: 700; color: var(--ink); }
.safe-header{
  display:flex; align-items:center; justify-content:space-between;
  background:linear-gradient(135deg, var(--sky), var(--mint));
  color:#003049; padding:18px 24px; border-radius:18px;
  box-shadow: 0 10px 24px rgba(0,0,0,.05);
}
.safe-header .left{ display:flex; align-items:center; gap:1rem; }
.safe-header img{ width:65px; height:auto; }
.safe-header .title{ font-size:22px; font-weight:700; }
.safe-header .desc{ font-size:13px; opacity:.85; }
.chat-wrap{
  margin-top:14px; background: var(--card); border-radius:24px;
  padding:14px 14px 6px; box-shadow: 0 8px 24px rgba(0,0,0,.06);
  border:1px solid rgba(0,0,0,.04);
  /* min-height: 400px;  <-- ì œê±°ë¨ */
}
.bubble{
  max-width: 84%; padding:12px 14px; border-radius:16px;
  margin:8px 0; line-height:1.45; word-break:keep-all; color:var(--ink);
  box-shadow: 0 2px 8px rgba(0,0,0,.04);
}
.bubble.user{
  margin-left:auto; background: var(--sky);
  border-top-right-radius:6px;
}
.bubble.ai{
  background: #fff; border:1px solid rgba(0,0,0,.05);
  border-top-left-radius:6px;
}
[data-testid="stSidebar"]{
  background:#ffffffcc; backdrop-filter: blur(6px);
  border-right:1px solid rgba(0,0,0,.06);
}
.sidebar-card{
  background:#fff; border:1px solid rgba(0,0,0,.05);
  border-radius:16px; padding:12px; margin-bottom:10px;
  box-shadow: 0 6px 16px rgba(0,0,0,.05);
}
.stButton>button{
  background: var(--coral); color:white; border:0; padding:.6rem 1rem;
  border-radius:12px; font-weight:700;
  box-shadow: 0 6px 18px rgba(255,154,162,.35);
}
.stButton>button:hover{ filter:brightness(.97); }
.stTextInput>div>div>input{
  border-radius:12px !important; border:1px solid rgba(0,0,0,.08);
  box-shadow: var(--ring);
}
footer.note{
  margin-top:10px; font-size:12px; color:#64748b;
  text-align:center;
}
</style>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ”¹ UI: í—¤ë” (ì´ë¯¸ì§€ í¬í•¨)
# ==========================================
if blue64 and pink64:
    img_type = "png" if blue64.startswith("data:image/png") else "jpeg"
    st.markdown(f"""
    <div class="safe-header">
      <div class="left">
        <img src="data:image/{img_type};base64,{blue64}" alt="blue medi">
        <div>
          <div class="title">SafeMedi AI</div>
          <div class="desc">ê·€ì—½ê³  ì§ê´€ì ì¸ ì•½ë¬¼ ì•ˆì „ ìƒë‹´ ì±—ë´‡</div>
        </div>
      </div>
      <img src="data:image/{img_type};base64,{pink64}" alt="pink medi">
    </div>
    """, unsafe_allow_html=True)
else:
    st.title("ğŸ’Š SafeMedi AI")
    st.caption("ê·€ì—½ê³  ì§ê´€ì ì¸ ì•½ë¬¼ ì•ˆì „ ìƒë‹´ ì±—ë´‡")


# ==========================================
# ğŸ”¹ UI: ë§í’ì„  í•¨ìˆ˜
# ==========================================
def bubble(role:str, text:str):
    cls = "ai" if role=="ai" else "user"
    
    if role == "user":
        text_to_render = html.escape(text)
    else:
        text_to_render = text # AI ë‹µë³€(HTML)ì€ ì´ìŠ¤ì¼€ì´í”„í•˜ì§€ ì•ŠìŒ
        
    st.markdown(f'<div class="bubble {cls}">{text_to_render}</div>', unsafe_allow_html=True)

# ==========================================
# ğŸ”¹ UI: ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.success(f"DB ì¤€ë¹„ ì™„ë£Œ\n(ì•½ë¬¼: {num_drugs}ê°œ, ì§ˆë³‘: {num_diseases}ê°œ, ìˆ˜ìˆ /ì‹œìˆ : {num_procedures}ê°œ)")
    st.markdown(f"<div style='font-size:12px; margin-top:-10px; margin-bottom:10px;'><b>LLM:</b> {CHAT_MODEL}</div>", unsafe_allow_html=True)
    
    st.markdown('<div class="sidebar-card"><b>ê²€ìƒ‰ ì˜µì…˜</b></div>', unsafe_allow_html=True)
    k_slider = st.slider("ë¬¸ì„œ ê²€ìƒ‰ ê°œìˆ˜ (k)", 3, 7, 4)
    only_preg = st.checkbox("ì„ë¶€ê¸ˆê¸° ì •ë³´ ìš°ì„  (ë¯¸ì ìš©)") 
    
    st.markdown('<div class="sidebar-card"><b>ë„ì›€ë§</b><br/>ì•½ ì´ë¦„ì´ë‚˜ ì¦ìƒìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš” ğŸ’¬</div>', unsafe_allow_html=True)
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.pop("history", None)
        st.rerun()

# ==========================================
# ğŸ”¹ UI: ì±„íŒ… ì˜ì—­
# ==========================================
st.markdown('<div class="chat-wrap">', unsafe_allow_html=True)

if "history" not in st.session_state:
    st.session_state.history = []  # [(role, text)]

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ëª¨ë‘ í‘œì‹œ
for role, txt in st.session_state.history:
    bubble(role, txt)

# ì±„íŒ… ì…ë ¥ì°½
query = st.chat_input("ì˜ˆ: ì„ì‹  ì¤‘ íƒ€ì´ë ˆë†€ ë³µìš©í•´ë„ ë˜ë‚˜ìš”?")

if query:
    # 1. ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ ë° ê¸°ë¡
    st.session_state.history.append(("user", query))
    bubble("user", query)
    
    original_question = query
    
    # 2. ëŒ€í™” ê¸°ë¡(Memory) ì¤€ë¹„ (LangChain í˜•ì‹)
    langchain_history = []
    for role, text in st.session_state.history[:-1]:
        if role == 'user':
            langchain_history.append(HumanMessage(content=text))
        else:
            langchain_history.append(AIMessage(content=text)) 

    # 3. [Chain 1] ì§ˆë¬¸ ì¬ì‘ì„± (Contextualizer)
    with st.spinner("ì§ˆë¬¸ ì˜ë„ ì´í•´ ì¤‘... (ì¬ì‘ì„±)"):
        try:
            rewritten_question = contextualizer_chain.invoke({
                "chat_history": langchain_history,
                "question": original_question
            }).strip()
            print(f"--- â“ ì›ë³¸ ì§ˆë¬¸: {original_question} ---")
            print(f"--- ğŸ”„ ì¬ì‘ì„±ëœ ì§ˆë¬¸: {rewritten_question} ---")
        except Exception as e:
            st.error(f"âŒ ì§ˆë¬¸ ì¬ì‘ì„± ì˜¤ë¥˜: {e}"); st.stop()

    # 4. [Chain 2] ë¼ìš°í„° í˜¸ì¶œ
    with st.spinner("ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì¤‘... (ë¼ìš°íŒ…)"):
        try:
            route_output = router_chain.invoke({"question": rewritten_question})
            route = route_output.strip().lower()
            print(f"--- ğŸ§­ ë¼ìš°íŒ… ê²°ê³¼: {route} ---")
        except Exception as e:
            st.error(f"âŒ ë¼ìš°í„° ì‹¤í–‰ ì˜¤ë¥˜: {e}"); st.stop()
    
    # 5. [Tool] Python ë¡œì§ìœ¼ë¡œ DB ê²€ìƒ‰
    response_text = ""
    context = None
    with st.spinner("ì „ë¬¸ê°€ DB ê²€ìƒ‰ ì¤‘..."):
        try:
            if "drug" in route:
                context = retrieve_drug_info(rewritten_question, k_slider)
            elif "disease" in route:
                context = retrieve_disease_info(rewritten_question, k_slider)
            elif "procedure" in route:
                context = retrieve_procedure_info(rewritten_question, k_slider)
            else:
                context = None 
                response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜ë£Œ ì •ë³´(ì•½ë¬¼, ì§ˆë³‘, ìˆ˜ìˆ )ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        except Exception as e:
            st.error(f"âŒ DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}"); st.stop()

    # 6. [Chain 3] ìš”ì•½ê¸° í˜¸ì¶œ (Streaming)
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘â€¦"):
        bubble_container = st.empty()
        streaming_answer = "" # ì›ë³¸ í…ìŠ¤íŠ¸ (ì´ìŠ¤ì¼€ì´í”„ ì•ˆë¨)
        
        if context is not None:
            try:
                for chunk in summarizer_chain.stream({
                    "context": context, 
                    "question": rewritten_question,
                    "chat_history": langchain_history
                }):
                    streaming_answer += chunk
                    # ìŠ¤íŠ¸ë¦¬ë°ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                    streaming_text_escaped = html.escape(streaming_answer)
                    bubble_container.markdown(f'<div class="bubble ai">{streaming_text_escaped}â–Œ</div>', unsafe_allow_html=True)
            except Exception as e:
                st.error(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                streaming_answer = "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        else:
            streaming_answer = response_text
        
        # ìµœì¢… ê¸°ë³¸ ë‹µë³€ì€ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        base_answer_escaped = html.escape(streaming_answer)

    # 7. [Chain 4] ì¶”ì²œ ì§ˆë¬¸ ìƒì„±
    recommendations_html = "" # HTMLì„ ì €ì¥í•  ë³€ìˆ˜
    
    # 1. DB ê²€ìƒ‰(context)ì´ ì„±ê³µí–ˆëŠ”ê°€?
    context_is_success = (
        context is not None and 
        "ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" not in context and 
        "ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤" not in context
    )
    
    # 2. AIì˜ ìµœì¢… ë‹µë³€(streaming_answer)ì´ ì„±ê³µí–ˆëŠ”ê°€? (í™˜ê° ë°©ì§€)
    failure_keywords = ["ì£„ì†¡í•©ë‹ˆë‹¤", "ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤", "ì¼ì¹˜í•˜ëŠ”", "ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "ê²€ìƒ‰ì–´ëŠ” ì—†ìŠµë‹ˆë‹¤"]
    answer_is_success = not any(keyword in streaming_answer for keyword in failure_keywords)

    # 3. ë‘˜ ë‹¤ ì„±ê³µí•´ì•¼ ì¶”ì²œ ì§ˆë¬¸ ì‹¤í–‰
    is_successful_answer = context_is_success and answer_is_success
    
    
    if is_successful_answer:
        with st.spinner("ğŸ” ê´€ë ¨ ì§ˆë¬¸ ì¶”ì²œ ì¤‘..."):
            try:
                # invokeì—ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸(streaming_answer)ë¥¼ ì‚¬ìš©
                recommendations_output = recommender_chain.invoke({"answer": streaming_answer})
                if "ì •ë³´ ì—†ìŒ" not in recommendations_output:
                    # ì¶”ì²œ ì§ˆë¬¸ì„ HTML í˜•ì‹ìœ¼ë¡œ ìƒì„±
                    recommendations_html = f"""
                    <div style="margin-top: 15px; font-size: 14px; border-top: 1px solid #eee; padding-top: 12px;">
                        <b style="color:var(--ink);">ğŸ’¡ ê´€ë ¨ ì¶”ì²œ ì§ˆë¬¸:</b><br>
                        {recommendations_output.replace('â€¢', 'â€¢ ').replace('\n', '<br>')}
                    </div>
                    """
            except Exception as e:
                print(f"--- âš ï¸ ì¶”ì²œ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e} ---")

    # 8. ìµœì¢… ë‹µë³€ ê²°í•© ë° ë Œë”ë§
    final_html_answer = base_answer_escaped + recommendations_html
    
    # 9. ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚œ bubble_containerë¥¼ ìµœì¢… HTML ë‹µë³€ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    bubble_container.markdown(f'<div class="bubble ai">{final_html_answer}</div>', unsafe_allow_html=True)
    
    # 10. ì´ ìµœì¢… HTML ë©ì–´ë¦¬ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state.history.append(("ai", final_html_answer))


st.markdown("</div>", unsafe_allow_html=True)
st.markdown('<footer class="note">â€» ë³¸ ì„œë¹„ìŠ¤ëŠ” ì •ë³´ ì œê³µìš©ì´ë©°, ì˜ë£Œ ì „ë¬¸ì˜ ìƒë‹´ì„ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</footer>', unsafe_allow_html=True)